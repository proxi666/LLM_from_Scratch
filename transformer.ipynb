{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Implementing a GPT model from Scratch to Generate Text\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024, # No of tokens porcessed at once\n",
    "    \"emb_dim\": 768, # dimensionality of the token embeddings also referred as d_in previously\n",
    "    \"n_heads\": 12, # No of attn heads\n",
    "    \"n_layers\": 12, # No of layers, Number of transformer block layer\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Architecture PART 1 : dummy GPT model class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):  # in_idx is the input which it takes\n",
    "        batch_size, seq_len = in_idx.shape  # Extract the batch size (number of sequences) and sequence length (number of tokens per sequence).\n",
    "        tok_embdd = self.tok_emb(in_idx)  # Compute token embeddings for the input indices using the token embedding layer.\n",
    "        pos_embdd = self.pos_emb(torch.arange(seq_len))  # Generate positional embeddings for each position in the sequence (0 to seq_len - 1).\n",
    "        x = tok_embdd + pos_embdd  # Combine token embeddings and positional embeddings element-wise.\n",
    "        x = self.drop_emb(x)  # Apply dropout to the combined embeddings for regularization.\n",
    "        x = self.trf_blocks(x)  # Pass the embeddings through the transformer blocks (e.g., multi-head attention and feed-forward layers).\n",
    "        x = self.final_norm(x)  # Apply layer normalization to the output of the transformer blocks.\n",
    "        logits = self.out_head(x)  # Compute the final output logits using the output head (e.g., a linear layer).\n",
    "        return logits  # Return the logits, which represent the model's predictions.\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare the input data and initialize a new GPT model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance of DummyGPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tensor has two rows corresponding to the two text samples. Each text sample consists of 4 tokens; each token is a 50,257-dimensional vector, which matches the size of the tokenizer's vocabulary.\n",
    "\n",
    "The embedding has 50,257 dimensions because each of these dimensions refers to a unique token in the vocabulary. At the end of this chapter, when we implement the postprocessing code, we will convert these 50,257-dimensional vectors back into token IDs, which we can then decode into words.\n",
    "\n",
    "Now that we have taken a top-down look at the GPT architecture and its in- and outputs, we will code the individual placeholders in the upcoming sections, starting with the real layer normalization class that will replace the DummyLayerNorm in the previous code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 2: LAYER NORMALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.6313, 0.7296, 0.2337],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4068, 0.8312, 0.2266]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create a random batch of input data with shape (batch_size, feature_dim)\n",
    "# feature_dim is the number of features(size of the vector) per token in the input data\n",
    "# Here, batch_size = 2 (2 examples) and feature_dim = 5 (5 features per example)\n",
    "batch_example = torch.randn(2, 5) \n",
    "\n",
    "# Define a simple neural network layer using nn.Sequential\n",
    "# nn.Sequential allows us to stack multiple layers together in sequence\n",
    "layer = nn.Sequential(\n",
    "    nn.Linear(5, 6),  # A linear (fully connected) layer with input size 5 and output size 6\n",
    "    nn.ReLU()         # A ReLU (Rectified Linear Unit) activation function\n",
    ")\n",
    "\n",
    "# Pass the batch of input data through the layer\n",
    "out = layer(batch_example)\n",
    "\n",
    "# Print the output\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.2658],\n",
      "        [0.2441]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.1123],\n",
      "        [0.1100]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True) # Compute the mean of the output tensor along the last dimension, keepdim=True ensures the output has the same number of dimensions as the input\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean) # Print the mean\n",
    "print(\"Variance:\\n\", var) # Print the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us apply layer normalization to the layer outputs we obtained earlier. The operation consists of subtracting the mean and dividing by the square root of the variance (also known as standard deviation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[-0.7930, -0.7930, -0.7930,  1.0905,  1.3839, -0.0955],\n",
      "        [-0.7358, -0.7358, -0.7358,  0.4905,  1.7698, -0.0528]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[ 9.9341e-08],\n",
      "        [-4.4703e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the value 2.9802e-08 in the output tensor is the scientific notation for 2.9802 × 10-8, which is 0.0000000298 in decimal form. This value is very close to 0, but it is not exactly 0 due to small numerical errors that can accumulate because of the finite precision with which computers represent numbers.\n",
    "\n",
    "\n",
    "To improve readability, we can also turn off the scientific notation when printing tensor values by setting sci_mode to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[     0.0000],\n",
      "        [    -0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim): \n",
    "        super().__init__() # Call the constructor of the nn.Module class\n",
    "        self.eps = 1e-5 # Define a small value epsilon to avoid division by zero\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim)) # Create a learnable parameter tensor for the scale factor with dimension emb_dim\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) # Create a learnable parameter tensor for the shift factor with dimension emb_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True) # Compute the mean of the input tensor along the last dimension\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) # Compute the variance of the input tensor along the last dimension\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps) # Normalize the input tensor by subtracting the mean and dividing by the square root of the variance\n",
    "        return self.scale * norm_x + self.shift # Apply the scale and shift parameters to the normalized tensor and return the result   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale and shift are two trainable parameters (of the same dimension as the input) that the LLM automatically adjusts during training if it is determined that doing so would improve the model's performance on its training task.\n",
    "\n",
    "This allows the model to learn appropriate scaling and shifting that best suit the data it is processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[     0.0000],\n",
      "        [    -0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's now try the LayerNorm module in practice and apply it to the batch input:\n",
    "\n",
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see based on the results, the layer normalization code works as expected and normalizes the values of each of the two inputs such that they have a mean of 0 and a variance of 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 3: FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement the GELU activation function approximation used by GPT-2:\n",
    "\n",
    "class GELU(nn.Module): # Define a new class GELU that inherits from nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x): # This code is basically the Mathematical formula to calculate GELU\n",
    "        return 0.5 * x * (1 + torch.tanh( # Compute the GELU activation function\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * # Define the scaling factor for the approximation of the Gaussian error function (erf)\n",
    "            (x + 0.044715 * torch.pow(x, 3)) # Compute the polynomial approximation for the GELU function\n",
    "        )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get an idea of what this GELU function looks like and how it compares to the ReLU function, let's plot these functions side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU() # Create instances of the GELU and ReLU activation functions\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the resulting plot, ReLU is a piecewise linear function that outputs the input directly if it is positive; otherwise, it outputs zero.\n",
    "\n",
    "GELU is a smooth, nonlinear function that approximates ReLU but with a non-zero gradient for negative values.\n",
    "\n",
    "The smoothness of GELU, as shown in the above figure, can lead to better optimization properties during training, as it allows for more nuanced adjustments to the model's parameters.\n",
    "\n",
    "In contrast, ReLU has a sharp corner at zero, which can sometimes make optimization harder, especially in networks that are very deep or have complex architectures.\n",
    "\n",
    "Moreover, unlike RELU, which outputs zero for any negative input, GELU allows for a small, non-zero output for negative values.\n",
    "\n",
    "This characteristic means that during the training process, neurons that receive negative input can still contribute to the learning process, albeit to a lesser extent than positive inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(  # Define a feed-forward neural network with two linear layers and a GELU activation function\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # A linear layer with input size emb_dim and output size 4 * emb_dim\n",
    "            GELU(),                                        # Apply the GELU activation function\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), # A linear layer with input size 4 * emb_dim and output size emb_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "# Let's use the GELU function to implement the small neural network module, FeedForward, that we will be using in the LLM's transformer block later:\n",
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FeedForward module we implemented in this section plays a crucial role in enhancing the model's ability to learn from and generalize the data.\n",
    "\n",
    "Although the input and output dimensions of this module are the same, it internally expands the embedding dimension into a higher-dimensional space through the first linear layer.\n",
    "\n",
    "This expansion is followed by a non-linear GELU activation, and then a contraction back to the original dimension with the second linear transformation.\n",
    "\n",
    "Such a design allows for the exploration of a richer representation space.\n",
    "\n",
    "Moreover, the uniformity in input and output dimensions simplifies the architecture by enabling the stacking of multiple layers, as we will do later, without the need to adjust dimensions between them, thus making the model more scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see how we can add shortcut connections to the forward method:\n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output # Add the output of the current layer to the input\n",
    "            else:\n",
    "                x = layer_output # If shortcut cannot be applied, just update x to the output of the current layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code implements a deep neural network with 5 layers, each consisting of a Linear layer and a GELU activation function.\n",
    "\n",
    "In the forward pass, we iteratively pass the input through the layers and optionally add the shortcut connections if the self.use_shortcut attribute is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use this code to first initialize a neural network without shortcut connections. \n",
    "# Here, each layer will be initialized such that it accepts an example with 3 input values and returns 3 output values. The last layer returns a single output value:\n",
    "\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False # Set use_shortcut to False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement a function that computes the gradients in the the model's backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss() # Mean Squared Error Loss function \n",
    "    loss = loss(output, target) \n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding code, we specify a loss function that computes how close the model output and a user-specified target (here, for simplicity, the value 0) are.\n",
    "\n",
    "Then, when calling loss.backward(), PyTorch computes the loss gradient for each layer in the model.\n",
    "\n",
    "We can iterate through the weight parameters via model.named_parameters().\n",
    "\n",
    "Suppose we have a 3×3 weight parameter matrix for a given layer.\n",
    "\n",
    "In that case, this layer will have 3×3 gradient values, and we print the mean absolute gradient of these 3×3 gradient values to obtain a single gradient value per layer to compare the gradients between layers more easily.\n",
    "\n",
    "In short, the .backward() method is a convenient method in PyTorch that computes loss gradients, which are required during model training, without implementing the math for the gradient calculation ourselves, thereby making working with deep neural networks much more accessible.\n",
    "\n",
    "Let's now use the print_gradients function and apply it to the model without skip connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see based on the output of the print_gradients function, the gradients become smaller as we progress from the last layer (layers.4) to the first layer (layers.0), which is a phenomenon called the vanishing gradient problem.\n",
    "Let's now instantiate a model with skip connections and see how it compares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694108307361603\n",
      "layers.2.0.weight has gradient mean of 0.3289699852466583\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True # Set use_shortcut to True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multihead Block   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will define the MultiHeadAttention module, which will be used in the transformer block:\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024, # No of tokens porcessed at once\n",
    "    \"emb_dim\": 768, # dimensionality of the token embeddings also referred as d_in previously\n",
    "    \"n_heads\": 12, # No of attn heads\n",
    "    \"n_layers\": 12, # No of layers, Number of transformer block layer\n",
    "    \"drop_rate\": 0.1, # Dropout rate\n",
    "    \"qkv_bias\": False # Whether to use bias in the query, key, and value projections\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention( \n",
    "            d_in=cfg[\"emb_dim\"], # d_in is the input dimension\n",
    "            d_out=cfg[\"emb_dim\"],  # d_out is the output dimension\n",
    "            context_length=cfg[\"context_length\"], # context_length is the maximum sequence length\n",
    "            num_heads=cfg[\"n_heads\"], # n_heads is the number of attention heads\n",
    "            dropout=cfg[\"drop_rate\"], # drop_rate is the dropout rate\n",
    "            qkv_bias=cfg[\"qkv_bias\"]) \n",
    "        self.ff = FeedForward(cfg) \n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"]) # Layer normalization for the attention block\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"]) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x) \n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x) \n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x) \n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given code defines a TransformerBlock class in PyTorch that includes a multi-head attention mechanism (MultiHeadAttention) and a feed forward network (FeedForward), both configured based on a provided configuration dictionary (cfg), such as GPT_CONFIG_124M\n",
    "\n",
    "Layer normalization (LayerNorm) is applied before each of these two components, and dropout is applied after them to regularize the model and prevent overfitting.\n",
    "\n",
    "This is also known as Pre-LayerNorm.\n",
    "\n",
    "Older architectures, such as the original transformer model, applied layer normalization after the self-attention and feed-forward networks instead, known as Post-LayerNorm, which often leads to worse training dynamics.\n",
    "\n",
    "The class also implements the forward pass, where each component is followed by a shortcut connection that adds the input of the block to its output. This critical feature helps gradients flow through the network during training and improves the learning of deep models\n",
    "\n",
    "Using the GPT_CONFIG_124M dictionary we defined earlier, let's instantiate a transformer block and feed it some sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "# Create sample input of shape [batch_size, num_tokens, emb_dim]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024, # No of tokens porcessed at once\n",
    "    \"emb_dim\": 768, # dimensionality of the token embeddings also referred as d_in previously\n",
    "    \"n_heads\": 12, # No of attn heads\n",
    "    \"n_layers\": 12, # No of layers, Number of transformer block layer\n",
    "    \"drop_rate\": 0.1, # Dropout rate\n",
    "    \"qkv_bias\": False # Whether to use bias in the query, key, and value projections\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"]) # initialize token embedding layer\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"]) # initialize positional embedding layer\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"]) # Apply dropout to the embeddings\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]) # initialize transformer blocks, 12 transofmer blocks in our case\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"]) # initialize layer normalization\n",
    "        self.out_head = nn.Linear(  \n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False # initialize output head \n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape # Extract the batch size and sequence length from the input tensor\n",
    "        tok_embeds = self.tok_emb(in_idx) # Step 1 : Compute token embeddings for the input indices\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device)) # Step 2 : Generate positional embeddings for each position in the sequence\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size] # Step 3 : Combine token embeddings and positional embeddings\n",
    "        x = self.drop_emb(x) # Step 4 : Apply dropout to the combined embeddings\n",
    "        x = self.trf_blocks(x) # Step 5 : Pass the embeddings through the transformer blocks\n",
    "        x = self.final_norm(x) # Step 6 : Apply layer normalization to the output of the transformer blocks\n",
    "        logits = self.out_head(x) # Step 7 : Compute the final output logits using the output head\n",
    "        return logits # Step 8 : Return the logits, which represent the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: idx is a (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "Step 2: Crop current context if it exceeds the supported context size E.g., if LLM supports only 5 tokens, and the context size is 10 then only the last 5 tokens are used as context\n",
    "\n",
    "Step 3: Focus only on the last time step, so that (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "\n",
    "Step 4: probas has shape (batch, vocab_size)\n",
    "\n",
    "Step 5: idx_next has shape (batch, 1)\n",
    "\n",
    "Step 6: Append sampled index to the running sequence, where idx has shape (batch, n_tokens+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceeding code, the generate_text_simple function, we use a softmax function to convert the logits into a probability distribution from which we identify the position with the highest value via torch.argmax.\n",
    "\n",
    "The softmax function is monotonic, meaning it preserves the order of its inputs when transformed into outputs.\n",
    "\n",
    "So, in practice, the softmax step is redundant since the position with the highest score in the softmax output tensor is the same position in the logit tensor.\n",
    "\n",
    "In other words, we could apply the torch.argmax function to the logits tensor directly and get identical results.\n",
    "\n",
    "However, we coded the conversion to illustrate the full process of transforming logits to probabilities, which can add additional intuition, such as that the model generates the most likely next token, which is known as greedy decoding.\n",
    "\n",
    "In the next chapter, when we will implement the GPT training code, we will also introduce additional sampling techniques where we modify the softmax outputs such that the model doesn't always select the most likely token, which introduces variability and creativity in the generated text.\n",
    "\n",
    "Let's now try out the generate_text_simple function with the \"Hello, I am\" context as model input\n",
    "First, we encode the input context into token IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context) # Encode the starting context using the tokenizer\n",
    "print(\"encoded:\", encoded) # Print the encoded tokens\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A # Convert the encoded tokens to a tensor and add a batch dimension \n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape) # Print the shape of the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we put the model into .eval() mode, which disables random components like dropout, which are only used during training, and use the generate_text_simple function on the encoded input tensor:\n",
    "We disable dropout since we are not training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #A # Set the model to evaluation mode (no training)\n",
    "out = generate_text_simple( # Generate text using the model\n",
    "model=model, # Pass the model \n",
    "idx=encoded_tensor, \n",
    "max_new_tokens=6,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# EVALUATING GENERATIVE TEXT MODELS\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Model class we coded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the generate_text_simple function from the previous chapter to generate text.\n",
    "\n",
    "In addition, we define two convenience functions, text_to_token_ids and token_ids_to_text, for converting between token and text representations that we use throughout this chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pre Training LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have an inputs tensor containing the token IDs for 2 training examples (rows)\n",
    "\n",
    "Corresponding to the inputs, the targets contain the desired token IDs that we want the model to generate\n",
    "\n",
    "Notice that the targets are the inputs shifted by 1 position, as explained in chapter 2 when we implemented the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feeding the inputs to the model, we obtain the logits vector for the 2 input examples that consist of 3 tokens each\n",
    "\n",
    "Each of the tokens is a 50,257-dimensional vector corresponding to the size of the vocabulary\n",
    "\n",
    "Applying the softmax function, we can turn the logits tensor into a tensor of the same dimension containing probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the previous chapter, we can apply the argmax function to convert the probability scores into predicted token IDs.\n",
    "\n",
    "The softmax function above produced a 50,257-dimensional vector for each token; the argmax function returns the position of the highest probability score in this vector, which is the predicted token ID for the given token.\n",
    "\n",
    "Since we have 2 input batches with 3 tokens each, we obtain 2 by 3 predicted token IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we decode these tokens, we find that these are quite different from the tokens we want the model to predict, namely the target tokens.\n",
    "\n",
    "That's because the model wasn't trained yet.\n",
    "\n",
    "To train the model, we need to know how far it is away from the correct predictions (targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1: (tensor([3626, 6100,  345]), <Encoding 'gpt2'>)\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {  (targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-entropy loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token probabilities corresponding to the target indices are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Initialize text index to 0\n",
    "# This index corresponds to the first text sequence in the batch\n",
    "text_idx = 0\n",
    "\n",
    "# Extract the predicted probabilities for the target tokens in the first text sequence\n",
    "# probas: A tensor of shape (batch_size, sequence_length, vocab_size) containing predicted probabilities\n",
    "# text_idx: Index of the text sequence in the batch (0 for the first sequence)\n",
    "# [0, 1, 2]: Indices of the positions in the sequence (e.g., first three tokens)\n",
    "# targets[text_idx]: The true token IDs for the text sequence (ground truth)\n",
    "# target_probas_1: A tensor containing the predicted probabilities for the true tokens at positions 0, 1, and 2\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "\n",
    "# Print the predicted probabilities for the target tokens in the first text sequence\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "# Update text index to 1\n",
    "# This index corresponds to the second text sequence in the batch\n",
    "text_idx = 1\n",
    "\n",
    "# Extract the predicted probabilities for the target tokens in the second text sequence\n",
    "# Similar to the first text sequence, but now for the second sequence in the batch\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "\n",
    "# Print the predicted probabilities for the target tokens in the second text sequence\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to maximize all these values, bringing them close to a probability of 1.\n",
    "\n",
    "In mathematical optimization, it is easier to maximize the logarithm of the probability score than the probability score itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Next, we compute the average log probability:\n",
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to make this average log probability as large as possible by optimizing the model weights.\n",
    "\n",
    "Due to the log, the largest possible value is 0, and we are currently far away from 0.\n",
    "\n",
    "In deep learning, instead of maximizing the average log-probability, it's a standard convention to minimize the negative average log-probability value; in our case, instead of maximizing -10.7722 so that it approaches 0, in deep learning, we would minimize 10.7722 so that it approaches 0.\n",
    "\n",
    "The value negative of -10.7722, i.e., 10.7722, is also called cross-entropy loss in deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch already implements a cross_entropy function that carries out the previous steps\n",
    "\n",
    "Before we apply the cross_entropy function, let's check the shape of the logits and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the cross_entropy function in PyTorch, we want to flatten these tensors by combining them over the batch dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the targets are the token IDs, which also represent the index positions in the logits tensors that we want to maximize.\n",
    "\n",
    "The cross_entropy function in PyTorch will automatically take care of applying the softmax and log-probability computation internally over those token indices in the logits that are to be maximized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A concept related to the cross-entropy loss is the perplexity of an LLM.\n",
    "\n",
    "The perplexity is simply the exponential of the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perplexity is often considered more interpretable because it can be understood as the effective vocabulary size that the model is uncertain about at each step (in the example above, that'd be 48,725 words or tokens).\n",
    "\n",
    "In other words, perplexity provides a measure of how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset.\n",
    "\n",
    "Similar to the loss, a lower perplexity indicates that the model predictions are closer to the actual distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"autoware.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Project Gutenberg EBook of The Bhagavad-Gita, by Anonymous\n",
      "\n",
      "This eBook is for the use of anyon\n"
     ]
    }
   ],
   "source": [
    "# A quick check that the text loaded ok by printing the first and last 100 words\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p produce our new eBooks, and how to\n",
      "subscribe to our email newsletter to hear about new eBooks.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 137483\n",
      "Tokens: 38552\n"
     ]
    }
   ],
   "source": [
    "# Now we tokenize the text data using the GPT-2 tokenizer\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import tiktoken  # For tokenization\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for preparing input-target pairs for GPT-style models.\n",
    "        \n",
    "        Args:\n",
    "            txt (str): The input text data.\n",
    "            tokenizer: Tokenizer to convert text into token IDs.\n",
    "            max_length (int): Maximum length of each input sequence.\n",
    "            stride (int): Step size for the sliding window to create overlapping sequences.\n",
    "        \"\"\"\n",
    "        self.input_ids = []  # Stores input sequences\n",
    "        self.target_ids = []  # Stores target sequences (shifted by 1 from input)\n",
    "\n",
    "        # Tokenize the entire text into token IDs\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the tokenized text into overlapping sequences\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            # Extract input sequence of length `max_length`\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            # Extract target sequence (shifted by 1 from input)\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            \n",
    "            # Convert lists to PyTorch tensors and store them\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of input-target pairs in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the input-target pair at the specified index.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): Index of the input-target pair to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (input_ids, target_ids) as PyTorch tensors.\n",
    "        \"\"\"\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "    \"\"\"\n",
    "    Creates a PyTorch DataLoader for the GPTDatasetV1.\n",
    "    \n",
    "    Args:\n",
    "        txt (str): The input text data.\n",
    "        batch_size (int): Number of sequences per batch.\n",
    "        max_length (int): Maximum length of each input sequence.\n",
    "        stride (int): Step size for the sliding window to create overlapping sequences.\n",
    "        shuffle (bool): Whether to shuffle the dataset.\n",
    "        drop_last (bool): Whether to drop the last incomplete batch.\n",
    "        num_workers (int): Number of subprocesses to use for data loading.\n",
    "    \n",
    "    Returns:\n",
    "        DataLoader: PyTorch DataLoader for the GPTDatasetV1.\n",
    "    \"\"\"\n",
    "    # Initialize the tokenizer (using GPT-2 tokenizer from tiktoken)\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,  # Number of sequences per batch\n",
    "        shuffle=shuffle,  # Shuffle the dataset\n",
    "        drop_last=drop_last,  # Drop the last incomplete batch\n",
    "        num_workers=num_workers  # Number of subprocesses for data loading\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "68\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 34816\n",
      "Validation tokens: 3072\n",
      "All tokens: 37888\n"
     ]
    }
   ],
   "source": [
    "# An optional check that the data was loaded correctly:\n",
    "\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Class that we had already coded\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement a utility function to calculate the cross-entropy loss of a given batch.\n",
    "\n",
    "In addition, we implement a second utility function to compute the loss for a user-specified number of batches in a data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    \"\"\"\n",
    "    Calculate the loss for a single batch of input-target pairs.\n",
    "    \n",
    "    Args:\n",
    "        input_batch (torch.Tensor): Input batch of token IDs (shape: [batch_size, seq_len]).\n",
    "        target_batch (torch.Tensor): Target batch of token IDs (shape: [batch_size, seq_len]).\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        device (torch.device): The device (e.g., \"cpu\" or \"cuda\") where the computation will be performed.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The computed loss for the batch.\n",
    "    \"\"\"\n",
    "    # Move input and target batches to the specified device (e.g., GPU)\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    \n",
    "    # Forward pass: compute logits (model predictions)\n",
    "    logits = model(input_batch)\n",
    "    \n",
    "    # Compute the cross-entropy loss between the logits and target batch\n",
    "    # Flatten the logits and targets to compute loss over all tokens in the batch\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"\n",
    "    Calculate the average loss over a DataLoader.\n",
    "    \n",
    "    Args:\n",
    "        data_loader (torch.utils.data.DataLoader): DataLoader providing input-target batches.\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        device (torch.device): The device (e.g., \"cpu\" or \"cuda\") where the computation will be performed.\n",
    "        num_batches (int, optional): Number of batches to evaluate. If None, evaluate all batches.\n",
    "    \n",
    "    Returns:\n",
    "        float: The average loss over the specified number of batches.\n",
    "    \"\"\"\n",
    "    total_loss = 0.  # Accumulator for total loss\n",
    "    \n",
    "    # Handle edge case: if the DataLoader is empty, return NaN\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    # If num_batches is not specified, evaluate all batches in the DataLoader\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # If num_batches is specified, ensure it does not exceed the total number of batches\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    # Iterate through the DataLoader\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        # Stop after processing the specified number of batches\n",
    "        if i < num_batches:\n",
    "            # Compute the loss for the current batch\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()  # Accumulate the loss\n",
    "        else:\n",
    "            break  # Exit the loop after processing the specified number of batches\n",
    "    \n",
    "    # Return the average loss over the processed batches\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "Current GPU: 0\n",
      "GPU Name: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "PyTorch version: 2.4.1\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Check the number of GPUs available\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "\n",
    "# Check the current GPU in use\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current GPU:\", torch.cuda.current_device())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.977344050126916\n",
      "Validation loss: 10.9678848584493\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# TRAINING LOOP FOR THE LLM\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1  # Track total tokens seen and global training steps\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode (enables dropout, batch norm, etc.)\n",
    "        \n",
    "        # Iterate over batches in the training data loader\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset gradients from the previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)  # Compute loss for the current batch\n",
    "            loss.backward()  # Perform backpropagation to compute gradients\n",
    "            optimizer.step()  # Update model weights using the computed gradients\n",
    "            tokens_seen += input_batch.numel()  # Update total tokens seen (numel() returns the total number of elements in the batch)\n",
    "            global_step += 1  # Increment global step counter\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:  # Evaluate the model at regular intervals\n",
    "                # Compute training and validation loss\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                # Append losses and tokens seen to their respective lists\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                # Print the current epoch, step, and losses\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch to monitor progress\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    # Return the tracked losses and tokens seen for analysis\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Initialize lists to track losses and tokens seen\n",
    "\n",
    "Step 2: Start the main training loop\n",
    "\n",
    "Step 3: Reset loss gradients from previous batch iteration\n",
    "\n",
    "Step 4: Calculate loss gradients\n",
    "\n",
    "Step 5: Update model weights using loss gradients\n",
    "\n",
    "Step 6: Optional evaluation step\n",
    "\n",
    "Step 7: Print a sample text after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    # Set the model to evaluation mode\n",
    "    # This disables features like dropout and batch normalization that are only used during training\n",
    "    model.eval()\n",
    "\n",
    "    # Use torch.no_grad() to disable gradient computation\n",
    "    # This reduces memory usage and speeds up computation since gradients are not needed for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Compute the training loss on a subset of the training data\n",
    "        # train_loader: DataLoader for the training dataset\n",
    "        # model: The model being evaluated\n",
    "        # device: The device (e.g., CPU or GPU) on which the computation is performed\n",
    "        # num_batches=eval_iter: Number of batches to evaluate (to limit computation time)\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "        # Compute the validation loss on a subset of the validation data\n",
    "        # val_loader: DataLoader for the validation dataset\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    # This re-enables features like dropout and batch normalization for subsequent training\n",
    "    model.train()\n",
    "\n",
    "    # Return the computed training and validation losses\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluate_model function calculates the loss over the training and validation set while ensuring the model is in evaluation mode with gradient tracking and dropout disabled when calculating the loss over the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    # Set the model to evaluation mode\n",
    "    # This disables features like dropout and batch normalization that are only used during training\n",
    "    model.eval()\n",
    "\n",
    "    # Get the context size from the model's positional embedding layer\n",
    "    # This determines the maximum sequence length the model can handle\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    # Convert the starting context text into token IDs using the tokenizer\n",
    "    # start_context: The initial text used to start text generation\n",
    "    # tokenizer: The tokenizer associated with the model\n",
    "    # device: The device (e.g., CPU or GPU) on which the computation is performed\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "\n",
    "    # Disable gradient computation for text generation\n",
    "    # This reduces memory usage and speeds up computation since gradients are not needed\n",
    "    with torch.no_grad():\n",
    "        # Generate text using the model\n",
    "        # model: The model used for text generation\n",
    "        # idx: The starting token IDs (encoded context)\n",
    "        # max_new_tokens: The maximum number of new tokens to generate\n",
    "        # context_size: The maximum sequence length the model can handle\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "\n",
    "    # Convert the generated token IDs back into text using the tokenizer\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    # Print the generated text in a compact format (replacing newlines with spaces)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    # This re-enables features like dropout and batch normalization for subsequent training\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.627, Val loss 10.004\n",
      "Ep 1 (Step 000005): Train loss 8.409, Val loss 8.616\n",
      "Ep 1 (Step 000010): Train loss 7.351, Val loss 7.982\n",
      "Ep 1 (Step 000015): Train loss 7.051, Val loss 7.823\n",
      "Ep 1 (Step 000020): Train loss 7.073, Val loss 7.868\n",
      "Ep 1 (Step 000025): Train loss 7.037, Val loss 8.030\n",
      "Ep 1 (Step 000030): Train loss 6.595, Val loss 8.026\n",
      "Ep 1 (Step 000035): Train loss 6.405, Val loss 7.812\n",
      "Ep 1 (Step 000040): Train loss 6.501, Val loss 7.792\n",
      "Ep 1 (Step 000045): Train loss 6.347, Val loss 7.806\n",
      "Ep 1 (Step 000050): Train loss 6.537, Val loss 7.889\n",
      "Ep 1 (Step 000055): Train loss 6.225, Val loss 7.906\n",
      "Ep 1 (Step 000060): Train loss 6.278, Val loss 7.900\n",
      "Ep 1 (Step 000065): Train loss 6.234, Val loss 7.971\n",
      "Every effort moves you, The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000070): Train loss 6.311, Val loss 7.914\n",
      "Ep 2 (Step 000075): Train loss 6.131, Val loss 7.796\n",
      "Ep 2 (Step 000080): Train loss 6.292, Val loss 7.885\n",
      "Ep 2 (Step 000085): Train loss 6.320, Val loss 7.838\n",
      "Ep 2 (Step 000090): Train loss 6.188, Val loss 7.954\n",
      "Ep 2 (Step 000095): Train loss 6.125, Val loss 8.056\n",
      "Ep 2 (Step 000100): Train loss 5.925, Val loss 7.870\n",
      "Ep 2 (Step 000105): Train loss 6.107, Val loss 7.915\n",
      "Ep 2 (Step 000110): Train loss 5.862, Val loss 7.959\n",
      "Ep 2 (Step 000115): Train loss 5.896, Val loss 8.071\n",
      "Ep 2 (Step 000120): Train loss 5.852, Val loss 7.989\n",
      "Ep 2 (Step 000125): Train loss 5.718, Val loss 8.041\n",
      "Ep 2 (Step 000130): Train loss 5.661, Val loss 7.982\n",
      "Ep 2 (Step 000135): Train loss 5.620, Val loss 7.936\n",
      "Every effort moves you                                                  \n",
      "Ep 3 (Step 000140): Train loss 5.661, Val loss 7.914\n",
      "Ep 3 (Step 000145): Train loss 5.610, Val loss 7.976\n",
      "Ep 3 (Step 000150): Train loss 5.515, Val loss 7.920\n",
      "Ep 3 (Step 000155): Train loss 5.664, Val loss 7.772\n",
      "Ep 3 (Step 000160): Train loss 5.719, Val loss 7.826\n",
      "Ep 3 (Step 000165): Train loss 5.417, Val loss 7.837\n",
      "Ep 3 (Step 000170): Train loss 5.272, Val loss 7.707\n",
      "Ep 3 (Step 000175): Train loss 5.601, Val loss 7.519\n",
      "Ep 3 (Step 000180): Train loss 5.077, Val loss 7.319\n",
      "Ep 3 (Step 000185): Train loss 5.120, Val loss 7.422\n",
      "Ep 3 (Step 000190): Train loss 5.065, Val loss 7.582\n",
      "Ep 3 (Step 000195): Train loss 5.102, Val loss 7.687\n",
      "Ep 3 (Step 000200): Train loss 4.917, Val loss 7.635\n",
      "Every effort moves you, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, \n",
      "Ep 4 (Step 000205): Train loss 4.716, Val loss 7.708\n",
      "Ep 4 (Step 000210): Train loss 4.668, Val loss 7.671\n",
      "Ep 4 (Step 000215): Train loss 4.610, Val loss 7.438\n",
      "Ep 4 (Step 000220): Train loss 4.760, Val loss 7.438\n",
      "Ep 4 (Step 000225): Train loss 4.879, Val loss 7.478\n",
      "Ep 4 (Step 000230): Train loss 4.222, Val loss 7.566\n",
      "Ep 4 (Step 000235): Train loss 4.462, Val loss 7.706\n",
      "Ep 4 (Step 000240): Train loss 4.250, Val loss 7.549\n",
      "Ep 4 (Step 000245): Train loss 4.468, Val loss 7.588\n",
      "Ep 4 (Step 000250): Train loss 3.940, Val loss 7.431\n",
      "Ep 4 (Step 000255): Train loss 4.221, Val loss 7.537\n",
      "Ep 4 (Step 000260): Train loss 4.299, Val loss 7.319\n",
      "Ep 4 (Step 000265): Train loss 4.402, Val loss 7.335\n",
      "Ep 4 (Step 000270): Train loss 4.074, Val loss 7.400\n",
      "Every effort moves you The gods The Book of the soul The Book of the \"The Book of the soul. The Book of the soul.    The Book of the soul  The Book of the soul.     \n",
      "Ep 5 (Step 000275): Train loss 4.126, Val loss 7.541\n",
      "Ep 5 (Step 000280): Train loss 4.132, Val loss 7.598\n",
      "Ep 5 (Step 000285): Train loss 3.789, Val loss 7.478\n",
      "Ep 5 (Step 000290): Train loss 4.000, Val loss 7.556\n",
      "Ep 5 (Step 000295): Train loss 3.637, Val loss 7.536\n",
      "Ep 5 (Step 000300): Train loss 3.521, Val loss 7.459\n",
      "Ep 5 (Step 000305): Train loss 3.715, Val loss 7.289\n",
      "Ep 5 (Step 000310): Train loss 3.522, Val loss 7.233\n",
      "Ep 5 (Step 000315): Train loss 3.525, Val loss 7.210\n",
      "Ep 5 (Step 000320): Train loss 3.801, Val loss 7.277\n",
      "Ep 5 (Step 000325): Train loss 3.220, Val loss 7.246\n",
      "Ep 5 (Step 000330): Train loss 3.326, Val loss 7.464\n",
      "Ep 5 (Step 000335): Train loss 3.235, Val loss 7.471\n",
      "Every effort moves you of the good                                               \n",
      "Ep 6 (Step 000340): Train loss 3.120, Val loss 7.492\n",
      "Ep 6 (Step 000345): Train loss 2.902, Val loss 7.493\n",
      "Ep 6 (Step 000350): Train loss 3.249, Val loss 7.601\n",
      "Ep 6 (Step 000355): Train loss 2.897, Val loss 7.626\n",
      "Ep 6 (Step 000360): Train loss 2.446, Val loss 7.303\n",
      "Ep 6 (Step 000365): Train loss 2.769, Val loss 7.220\n",
      "Ep 6 (Step 000370): Train loss 2.845, Val loss 7.253\n",
      "Ep 6 (Step 000375): Train loss 2.675, Val loss 7.323\n",
      "Ep 6 (Step 000380): Train loss 2.647, Val loss 7.322\n",
      "Ep 6 (Step 000385): Train loss 2.875, Val loss 7.351\n",
      "Ep 6 (Step 000390): Train loss 2.185, Val loss 7.556\n",
      "Ep 6 (Step 000395): Train loss 2.165, Val loss 7.370\n",
      "Ep 6 (Step 000400): Train loss 2.354, Val loss 7.224\n",
      "Ep 6 (Step 000405): Train loss 2.167, Val loss 7.353\n",
      "Every effort moves you are not.                     The gift,                      The\n",
      "Ep 7 (Step 000410): Train loss 2.274, Val loss 7.357\n",
      "Ep 7 (Step 000415): Train loss 2.003, Val loss 7.408\n",
      "Ep 7 (Step 000420): Train loss 1.789, Val loss 7.417\n",
      "Ep 7 (Step 000425): Train loss 1.825, Val loss 7.396\n",
      "Ep 7 (Step 000430): Train loss 1.646, Val loss 7.530\n",
      "Ep 7 (Step 000435): Train loss 1.617, Val loss 7.440\n",
      "Ep 7 (Step 000440): Train loss 1.363, Val loss 7.490\n",
      "Ep 7 (Step 000445): Train loss 1.353, Val loss 7.522\n",
      "Ep 7 (Step 000450): Train loss 1.574, Val loss 7.585\n",
      "Ep 7 (Step 000455): Train loss 1.397, Val loss 7.494\n",
      "Ep 7 (Step 000460): Train loss 1.290, Val loss 7.622\n",
      "Ep 7 (Step 000465): Train loss 1.455, Val loss 7.487\n",
      "Ep 7 (Step 000470): Train loss 1.109, Val loss 7.633\n",
      "Ep 7 (Step 000475): Train loss 1.215, Val loss 7.546\n",
      "Every effort moves you are not.            To find the \"dark.\"                                   \n",
      "Ep 8 (Step 000480): Train loss 1.060, Val loss 7.643\n",
      "Ep 8 (Step 000485): Train loss 0.992, Val loss 7.716\n",
      "Ep 8 (Step 000490): Train loss 0.962, Val loss 7.583\n",
      "Ep 8 (Step 000495): Train loss 1.089, Val loss 7.702\n",
      "Ep 8 (Step 000500): Train loss 0.962, Val loss 7.758\n",
      "Ep 8 (Step 000505): Train loss 0.906, Val loss 7.837\n",
      "Ep 8 (Step 000510): Train loss 0.895, Val loss 7.792\n",
      "Ep 8 (Step 000515): Train loss 0.844, Val loss 7.847\n",
      "Ep 8 (Step 000520): Train loss 0.977, Val loss 7.723\n",
      "Ep 8 (Step 000525): Train loss 0.794, Val loss 7.712\n",
      "Ep 8 (Step 000530): Train loss 0.819, Val loss 7.716\n",
      "Ep 8 (Step 000535): Train loss 0.713, Val loss 7.749\n",
      "Ep 8 (Step 000540): Train loss 0.743, Val loss 7.707\n",
      "Every effort moves you are sped and \"Gunatas, and the company               And ADHIYAJNA, and worship be--serene--          \n",
      "Ep 9 (Step 000545): Train loss 0.722, Val loss 7.855\n",
      "Ep 9 (Step 000550): Train loss 0.689, Val loss 7.795\n",
      "Ep 9 (Step 000555): Train loss 0.656, Val loss 7.745\n",
      "Ep 9 (Step 000560): Train loss 0.672, Val loss 7.878\n",
      "Ep 9 (Step 000565): Train loss 0.657, Val loss 7.839\n",
      "Ep 9 (Step 000570): Train loss 0.481, Val loss 7.840\n",
      "Ep 9 (Step 000575): Train loss 0.453, Val loss 7.932\n",
      "Ep 9 (Step 000580): Train loss 0.578, Val loss 7.842\n",
      "Ep 9 (Step 000585): Train loss 0.379, Val loss 7.877\n",
      "Ep 9 (Step 000590): Train loss 0.509, Val loss 8.026\n",
      "Ep 9 (Step 000595): Train loss 0.385, Val loss 7.991\n",
      "Ep 9 (Step 000600): Train loss 0.432, Val loss 7.820\n",
      "Ep 9 (Step 000605): Train loss 0.379, Val loss 7.787\n",
      "Ep 9 (Step 000610): Train loss 0.405, Val loss 7.803\n",
      "Every effort moves you no work was.  Hear from me, Long-armed Lord! the makings five Which go to every act, in Sankhya taught As necessary. First the force; and then The agent; next, the various\n",
      "Ep 10 (Step 000615): Train loss 0.353, Val loss 7.859\n",
      "Ep 10 (Step 000620): Train loss 0.387, Val loss 7.848\n",
      "Ep 10 (Step 000625): Train loss 0.321, Val loss 8.015\n",
      "Ep 10 (Step 000630): Train loss 0.367, Val loss 8.037\n",
      "Ep 10 (Step 000635): Train loss 0.400, Val loss 7.928\n",
      "Ep 10 (Step 000640): Train loss 0.266, Val loss 8.061\n",
      "Ep 10 (Step 000645): Train loss 0.283, Val loss 7.986\n",
      "Ep 10 (Step 000650): Train loss 0.351, Val loss 7.992\n",
      "Ep 10 (Step 000655): Train loss 0.265, Val loss 8.035\n",
      "Ep 10 (Step 000660): Train loss 0.289, Val loss 8.069\n",
      "Ep 10 (Step 000665): Train loss 0.300, Val loss 7.978\n",
      "Ep 10 (Step 000670): Train loss 0.263, Val loss 7.939\n",
      "Ep 10 (Step 000675): Train loss 0.254, Val loss 7.956\n",
      "Every effort moves you are sped That man, and horns In all beings! Whoso, and tender its piety, and straight did take And live could fall to a work grievous to birth, and intellect.    That the Eternal God!\n",
      "Training completed in 3.10 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()  # Record the start time of the training process\n",
    "\n",
    "# Set a manual seed for reproducibility\n",
    "# This ensures that the random initialization of model weights and other random processes are consistent\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Initialize the GPT model with the specified configuration (GPT_CONFIG_124M)\n",
    "# GPT_CONFIG_124M: A dictionary or object containing hyperparameters for the model\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# Move the model to the specified device (e.g., CPU or GPU)\n",
    "model.to(device)\n",
    "\n",
    "# Initialize the optimizer (AdamW) for training the model\n",
    "# AdamW is a variant of Adam that includes weight decay for regularization\n",
    "# lr=0.0004: Learning rate for the optimizer\n",
    "# weight_decay=0.1: Weight decay (L2 regularization) to prevent overfitting\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "# Set the number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Train the model using the train_model_simple function\n",
    "# train_model_simple: A custom function to handle the training loop\n",
    "# model: The GPT model to be trained\n",
    "# train_loader: DataLoader for the training dataset\n",
    "# val_loader: DataLoader for the validation dataset\n",
    "# optimizer: The optimizer used for training\n",
    "# device: The device (e.g., CPU or GPU) on which the training is performed\n",
    "# num_epochs: Number of epochs to train the model\n",
    "# eval_freq: Frequency of evaluation (e.g., evaluate every 5 steps)\n",
    "# eval_iter: Number of batches to use for each evaluation\n",
    "# start_context: Initial text used for generating samples during training\n",
    "# tokenizer: Tokenizer associated with the model\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()  # Record the end time of the training process\n",
    "execution_time_minutes = (end_time - start_time) / 60  # Calculate the total execution time in minutes\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")  # Print the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the training and validation losses start to improve for the first epoch. However, the losses start to diverge past the second epoch.\n",
    "\n",
    "This divergence and the fact that the validation loss is much larger than the training loss indicate that the model is overfitting to the training data.\n",
    "\n",
    "This memorization is expected since we are working with a very, very small training dataset and training the model for multiple epochs.\n",
    "\n",
    "Usually, it's common to train a model on a much, much larger dataset for only one epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temprature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, inside the generate_text_simple function, we always sampled the token with the highest probability as the next token using torch.argmax, also known as greedy decoding.\n",
    "\n",
    "To generate text with more variety, we can replace the argmax with a function that samples from a probability distribution (here, the probability scores the LLM generates for each vocabulary entry at each token generation step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the probabilistic sampling with a concrete example, let's briefly discuss the next-token generation process using a very small vocabulary for illustration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, assume the LLM is given the start context \"every effort moves you\" and generates the following next-token logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "next_token_logits2 = next_token_logits/0.1\n",
    "\n",
    "next_token_logits3 = next_token_logits/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the previous chapter, inside the generate_text_simple, we convert the logits into probabilities via the softmax function and obtain the token ID corresponding the generated token via the argmax function, which we can then map back into text via the inverse vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0.0000,     0.0000,     0.0000,     0.9910,     0.0000,     0.0000,\n",
      "            0.0000,     0.0090,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits2, dim=0)\n",
    "\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits3, dim=0)\n",
    "\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0.0609,     0.0016,     0.0001,     0.5721,     0.0034,     0.0001,\n",
      "            0.0001,     0.3576,     0.0040])\n",
      "3\n",
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "\n",
    "print(probas)\n",
    "\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "print(next_token_id)\n",
    "\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement a probabilistic sampling process, we can now replace the argmax with the multinomial function in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printed output is \"forward\" just like before. What happened? The multinomial function samples the next token proportional to its probability score.\n",
    "\n",
    "In other words, \"forward\" is still the most likely token and will be selected by multinomial most of the time but not all the time.\n",
    "\n",
    "To illustrate this, let's implement a function that repeats this sampling 1000 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see based on the output, the word \"forward\" is sampled most of the time (582 out of 1000 times), but other tokens such as \"closer\", \"inches\", and \"toward\" will also be sampled some of the time.\n",
    "\n",
    "This means that if we replaced the argmax function with the multinomial function inside the generate_and_print_sample function, the LLM would sometimes generate texts such as \"every effort moves you toward\", \"every effort moves you inches\", and \"every effort moves you closer\" instead of \"every effort moves you forward\".\n",
    "\n",
    "We can further control the distribution and selection process via a concept called temperature scaling, where temperature scaling is just a fancy description for dividing the logits by a number greater than 0:\n",
    "\n",
    "Temperatures greater than 1 result in more uniformly distributed token probabilities, and Temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions.\n",
    "\n",
    "Let's illustrate this by plotting the original probabilities alongside probabilities scaled with different temperature values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "\n",
    "##Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temperature of 1 divides the logits by 1 before passing them to the softmax function to compute the probability scores.\n",
    "\n",
    "In other words, using a temperature of 1 is the same as not using any temperature scaling.\n",
    "\n",
    "In this case, the tokens are selected with a probability equal to the original softmax probability scores via the multinomial sampling function in PyTorch.\n",
    "\n",
    "Applying very small temperatures, such as 0.1, will result in sharper distributions such that the behavior of the multinomial function selects the most likely token (here: \"forward\") almost 100% of the time, approaching the behavior of the argmax function.\n",
    "\n",
    "Vice versa, a temperature of 5 results in a more uniform distribution where other tokens are selected more often.\n",
    "\n",
    "This can add more variety to the generated texts but also more often results in nonsensical text.\n",
    "\n",
    "For example, using the temperature of 5 results in texts such as \"every effort moves you pizza\" about 4% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECODING STRATEGY 2: Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we implemented a probabilistic sampling approach coupled with temperature scaling to increase the diversity of the outputs.\n",
    "\n",
    "We saw that higher temperature values result in more uniformly distributed next-token probabilities, which result in more diverse outputs as it reduces the likelihood of the model repeatedly selecting the most probable token.\n",
    "\n",
    "This method allows for exploring less likely but potentially more interesting and creative paths in the generation process.\n",
    "\n",
    "However, One downside of this approach is that it sometimes leads to grammatically incorrect or completely nonsensical outputs such as \"every effort moves you pizza\".\n",
    "\n",
    "In this section, we introduce another concept called top-k sampling, which, when combined with probabilistic sampling and temperature scaling, can improve the text generation results.\n",
    "\n",
    "In top-k sampling, we can restrict the sampled tokens to the top-k most likely tokens and exclude all other tokens from the selection process by masking their probability scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequently, we apply PyTorch's where function to set the logit values of tokens that are below the lowest logit value within our top-3 selection to negative infinity (-inf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Lastly, let's apply the softmax function to turn these into next-token probabilities:\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Temperature Scaling and Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply the temperature scaling and multinomial function for probabilistic sampling introduced in the previous section to select the next token among these 3 nonzero probability scores to generate the next token. We do this in the next section by modifying the text generation function.\n",
    "\n",
    "The previous two subsections introduced two concepts to increase the diversity of LLMgenerated text: temperature sampling and top-k sampling. In this section, we combine and add these concepts to modify the generate_simple function we used to generate text via the LLM earlier, creating a new generate function:\n",
    "\n",
    "Step 1: For-loop is the same as before: Get logits, and only focus on last time step\n",
    "\n",
    "Step 2: In this new section, we filter logits with top_k sampling\n",
    "\n",
    "Step 3: This is the new section where we apply temperature scaling\n",
    "\n",
    "Step 4: Carry out greedy next-token selection as before when temperature scaling is disabled\n",
    "\n",
    "Step 5: Stop generating early if end-of-sequence token is encountered and eos_id is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you if all men of all th'n views and knows whose soul is piety\n"
     ]
    }
   ],
   "source": [
    "# Ensure the model is on the GPU\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Generate text\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(\"cuda\"),  # Move input to GPU\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "# Decode and print the output text\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINETUNING FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "# DOWNLOAD DATASET\n",
    "\n",
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the preceding code, the dataset is saved as a tab-separated text file, SMSSpamCollection.tsv, in the sms_spam_collection folder.\n",
    "\n",
    "We can load it into a pandas DataFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the previous code to balance the dataset, we can see that we now have equal amounts of spam and non-spam messages:\n",
    "\n",
    "Next, we convert the \"string\" class labels \"ham\" and \"spam\" into integer class labels 0 and 1, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is similar to converting text into token IDs.\n",
    "\n",
    "However, instead of using the GPT vocabulary, which consists of more than 50,000 words, we are dealing with just two token IDs: 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a random_split function to split the dataset into three parts: 70% for training, 10% for validation, and 20% for testing.\n",
    "\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionally, we save the dataset as CSV (comma-separated value) files, which we can reuse later:\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING DATALOADERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
